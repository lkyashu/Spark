# Spark Project for Basic Concepts using Scala
 
A sample Spark project with Scala to demonstrate how to manage the cleansing, scrubbing, curation, cleanup, sanitization, preprocessing, transformation, ETL and schema migration of unpredicted data sets using Spark core and Dataframe functions.

This can help you get an idea to answer interview questions related to core concept.

I haven't focused much on the project cleanup or modularizing it. Though necessary comments are added for clear understanding. Also there is a document Spark_hackathon_task which will brief about the task assigned as part of a hackathon.

## It will easily clear the core concept related to 

Downloading the data into HDFS location (/user/hduser/sparkhack2) and start progress.

Importing required classes including sparkcontext, sqlcontext and other required objects, classes.

Create Sparkcontext, sqlcontext or spark session.

You can learn how to remove header row, incomplete rows, rows with incomplete dataconversion to RDD and dataframes, creation of DSL column management function.

Also included is some screenshots when this is running showcasing information about jobs, stages and storage.
